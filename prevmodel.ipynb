{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Name: Sushant Pokharel \n",
    ">\n",
    "> ID: NP03A190316"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Long Short-Term Memory (LSTM) Model to Predict Stock Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminologes used: \n",
    "\n",
    "---\n",
    "\n",
    "- **Epoch**  =>  Passing the input data through the network and optimizing the weights once, is one epoch. <br/>\n",
    "\n",
    "\n",
    "- **Batch**  =>  The training data is divided into batches. Theoretically one can feed all the training data into a network at once, but practically it is limited to the computerâ€™s memory. <br/>\n",
    "\n",
    "\n",
    "- **Error function**  =>  E(y, t), where y is the output of the network and t is some target value. Minimizing the error function is equal to training the network. Mean squared error, MSE = p.square(np.subtract(Y_true,Y_pred)).mean() <br/>\n",
    "\n",
    "\n",
    "- **LSTM network**  =>  A recurrent network structure which is capable of learning long-term dependencies. <br/>\n",
    "\n",
    "\n",
    "- **Min-Max Scaling**  =>  A normalization method. all features will be transformed into the range [0,1] meaning that the minimum and maximum value of a feature/variable is going to be 0 and 1, respectively. <br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "---\n",
    "### Company: Nepal Telecom \n",
    "\n",
    "\n",
    "### Duration: From year 2010 to 2020\n",
    "\n",
    "\n",
    "> Source: https://www.kaggle.com/dklbbk/nepaltelecom-stock-price\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In sequence prediction problems such as Stock Price prediction, LSTM are powerful as they have ability to store past information in memory. This feature is very applicable in this project because previous prices are crutial to predict future price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will start by importing required dependencies: Numpy, Pandas, Matplotlib and MinMax Scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now store dataset into the variable df. \n",
    "\n",
    "### date_parser is used to convert string columns into array of date-time instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ntcprice.csv', date_parser = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>Date</th>\n",
       "      <th>No. of Transaction</th>\n",
       "      <th>Max Price</th>\n",
       "      <th>Min Price</th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>Traded Shares</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Prev. Closing</th>\n",
       "      <th>Difference(Rs)</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>37</td>\n",
       "      <td>623.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>6310</td>\n",
       "      <td>3886900</td>\n",
       "      <td>623.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>39</td>\n",
       "      <td>649.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>3034</td>\n",
       "      <td>1896758</td>\n",
       "      <td>662.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>134</td>\n",
       "      <td>662.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>28830</td>\n",
       "      <td>19005838</td>\n",
       "      <td>659.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>47</td>\n",
       "      <td>664.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>6455</td>\n",
       "      <td>4254337</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>45</td>\n",
       "      <td>668.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>3815</td>\n",
       "      <td>2506070</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>48</td>\n",
       "      <td>660.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>7225</td>\n",
       "      <td>4735546</td>\n",
       "      <td>653.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>166</td>\n",
       "      <td>670.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>15459</td>\n",
       "      <td>10112842</td>\n",
       "      <td>659.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>38</td>\n",
       "      <td>659.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>3210900</td>\n",
       "      <td>641.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>20</td>\n",
       "      <td>643.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>2262</td>\n",
       "      <td>1443946</td>\n",
       "      <td>636.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>31</td>\n",
       "      <td>652.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>1808</td>\n",
       "      <td>1152456</td>\n",
       "      <td>643.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-1.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SN        Date  No. of Transaction  Max Price  Min Price  Closing Price  \\\n",
       "0   1  2020-01-01                  37      623.0      612.0          619.0   \n",
       "1   2  2019-12-31                  39      649.0      620.0          623.0   \n",
       "2   3  2019-12-30                 134      662.0      655.0          662.0   \n",
       "3   4  2019-12-29                  47      664.0      658.0          659.0   \n",
       "4   5  2019-12-26                  45      668.0      654.0          657.0   \n",
       "5   6  2019-12-25                  48      660.0      650.0          657.0   \n",
       "6   7  2019-12-24                 166      670.0      650.0          653.0   \n",
       "7   8  2019-12-23                  38      659.0      637.0          659.0   \n",
       "8   9  2019-12-22                  20      643.0      635.0          641.0   \n",
       "9  10  2019-12-19                  31      652.0      632.0          636.0   \n",
       "\n",
       "   Traded Shares  Total Amount  Prev. Closing  Difference(Rs)  % Change  \n",
       "0           6310       3886900          623.0            -4.0     -0.64  \n",
       "1           3034       1896758          662.0           -39.0     -5.89  \n",
       "2          28830      19005838          659.0             3.0      0.46  \n",
       "3           6455       4254337          657.0             2.0      0.30  \n",
       "4           3815       2506070          657.0             0.0      0.00  \n",
       "5           7225       4735546          653.0             4.0      0.61  \n",
       "6          15459      10112842          659.0            -6.0     -0.91  \n",
       "7           5000       3210900          641.0            18.0      2.81  \n",
       "8           2262       1443946          636.0             5.0      0.79  \n",
       "9           1808       1152456          643.0            -7.0     -1.09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>Date</th>\n",
       "      <th>No. of Transaction</th>\n",
       "      <th>Max Price</th>\n",
       "      <th>Min Price</th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>Traded Shares</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Prev. Closing</th>\n",
       "      <th>Difference(Rs)</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2191</td>\n",
       "      <td>2010-04-27</td>\n",
       "      <td>11</td>\n",
       "      <td>448.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>3030</td>\n",
       "      <td>1335440</td>\n",
       "      <td>445.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2192</td>\n",
       "      <td>2010-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>448.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>1200</td>\n",
       "      <td>534700</td>\n",
       "      <td>455.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2193</td>\n",
       "      <td>2010-04-25</td>\n",
       "      <td>10</td>\n",
       "      <td>455.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>2310</td>\n",
       "      <td>1035190</td>\n",
       "      <td>440.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2194</td>\n",
       "      <td>2010-04-22</td>\n",
       "      <td>5</td>\n",
       "      <td>440.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1250</td>\n",
       "      <td>542850</td>\n",
       "      <td>443.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>2195</td>\n",
       "      <td>2010-04-21</td>\n",
       "      <td>10</td>\n",
       "      <td>444.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>882540</td>\n",
       "      <td>444.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2196</td>\n",
       "      <td>2010-04-20</td>\n",
       "      <td>7</td>\n",
       "      <td>445.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>3870</td>\n",
       "      <td>1708480</td>\n",
       "      <td>441.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2197</td>\n",
       "      <td>2010-04-19</td>\n",
       "      <td>3</td>\n",
       "      <td>445.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>400</td>\n",
       "      <td>177500</td>\n",
       "      <td>442.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>2198</td>\n",
       "      <td>2010-04-15</td>\n",
       "      <td>13</td>\n",
       "      <td>455.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1464600</td>\n",
       "      <td>414.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>2199</td>\n",
       "      <td>2010-04-15</td>\n",
       "      <td>13</td>\n",
       "      <td>455.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1464600</td>\n",
       "      <td>414.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>2200</td>\n",
       "      <td>2010-04-15</td>\n",
       "      <td>13</td>\n",
       "      <td>455.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1464600</td>\n",
       "      <td>414.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SN        Date  No. of Transaction  Max Price  Min Price  \\\n",
       "2190  2191  2010-04-27                  11      448.0      433.0   \n",
       "2191  2192  2010-04-26                   3      448.0      441.0   \n",
       "2192  2193  2010-04-25                  10      455.0      440.0   \n",
       "2193  2194  2010-04-22                   5      440.0      433.0   \n",
       "2194  2195  2010-04-21                  10      444.0      438.0   \n",
       "2195  2196  2010-04-20                   7      445.0      440.0   \n",
       "2196  2197  2010-04-19                   3      445.0      441.0   \n",
       "2197  2198  2010-04-15                  13      455.0      422.0   \n",
       "2198  2199  2010-04-15                  13      455.0      422.0   \n",
       "2199  2200  2010-04-15                  13      455.0      422.0   \n",
       "\n",
       "      Closing Price  Traded Shares  Total Amount  Prev. Closing  \\\n",
       "2190          445.0           3030       1335440          445.0   \n",
       "2191          445.0           1200        534700          455.0   \n",
       "2192          455.0           2310       1035190          440.0   \n",
       "2193          440.0           1250        542850          443.0   \n",
       "2194          443.0           2000        882540          444.0   \n",
       "2195          444.0           3870       1708480          441.0   \n",
       "2196          441.0            400        177500          442.0   \n",
       "2197          455.0           3300       1464600          414.0   \n",
       "2198          455.0           3300       1464600          414.0   \n",
       "2199          455.0           3300       1464600          414.0   \n",
       "\n",
       "      Difference(Rs)  % Change  \n",
       "2190             0.0      0.00  \n",
       "2191           -10.0     -2.20  \n",
       "2192            15.0      3.41  \n",
       "2193            -3.0     -0.68  \n",
       "2194            -1.0     -0.23  \n",
       "2195             3.0      0.68  \n",
       "2196            -1.0     -0.23  \n",
       "2197            41.0      9.90  \n",
       "2198            41.0      9.90  \n",
       "2199            41.0      9.90  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and testing sets\n",
    "\n",
    "### Using this code we will be able to train our model on data form year 2010 to 1st of jan 2019\n",
    "### We will test the model on data from 1st of jan 2019 to 1st of jan 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = df[df['Date']<'2018-01-01'].copy()\n",
    "data_test = df[df['Date']>='2018-01-01'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>Date</th>\n",
       "      <th>No. of Transaction</th>\n",
       "      <th>Max Price</th>\n",
       "      <th>Min Price</th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>Traded Shares</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Prev. Closing</th>\n",
       "      <th>Difference(Rs)</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>486</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>77</td>\n",
       "      <td>827.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>17490</td>\n",
       "      <td>13666590</td>\n",
       "      <td>843.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>487</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>150</td>\n",
       "      <td>850.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>122210</td>\n",
       "      <td>103049079</td>\n",
       "      <td>839.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>488</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>114</td>\n",
       "      <td>848.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>45171</td>\n",
       "      <td>37511305</td>\n",
       "      <td>860.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>489</td>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>245</td>\n",
       "      <td>867.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>82110</td>\n",
       "      <td>69226205</td>\n",
       "      <td>850.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>490</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>168</td>\n",
       "      <td>872.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>30830</td>\n",
       "      <td>26285395</td>\n",
       "      <td>860.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-1.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SN        Date  No. of Transaction  Max Price  Min Price  Closing Price  \\\n",
       "485  486  2017-12-31                  77      827.0      772.0          778.0   \n",
       "486  487  2017-12-28                 150      850.0      837.0          843.0   \n",
       "487  488  2017-12-27                 114      848.0      811.0          839.0   \n",
       "488  489  2017-12-26                 245      867.0      839.0          860.0   \n",
       "489  490  2017-12-24                 168      872.0      840.0          850.0   \n",
       "\n",
       "     Traded Shares  Total Amount  Prev. Closing  Difference(Rs)  % Change  \n",
       "485          17490      13666590          843.0           -65.0     -7.71  \n",
       "486         122210     103049079          839.0             4.0      0.48  \n",
       "487          45171      37511305          860.0           -21.0     -2.44  \n",
       "488          82110      69226205          850.0            10.0      1.18  \n",
       "489          30830      26285395          860.0           -10.0     -1.16  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>Date</th>\n",
       "      <th>No. of Transaction</th>\n",
       "      <th>Max Price</th>\n",
       "      <th>Min Price</th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>Traded Shares</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Prev. Closing</th>\n",
       "      <th>Difference(Rs)</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>37</td>\n",
       "      <td>623.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>6310</td>\n",
       "      <td>3886900</td>\n",
       "      <td>623.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>39</td>\n",
       "      <td>649.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>3034</td>\n",
       "      <td>1896758</td>\n",
       "      <td>662.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>134</td>\n",
       "      <td>662.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>28830</td>\n",
       "      <td>19005838</td>\n",
       "      <td>659.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>47</td>\n",
       "      <td>664.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>6455</td>\n",
       "      <td>4254337</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>45</td>\n",
       "      <td>668.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>3815</td>\n",
       "      <td>2506070</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SN        Date  No. of Transaction  Max Price  Min Price  Closing Price  \\\n",
       "0   1  2020-01-01                  37      623.0      612.0          619.0   \n",
       "1   2  2019-12-31                  39      649.0      620.0          623.0   \n",
       "2   3  2019-12-30                 134      662.0      655.0          662.0   \n",
       "3   4  2019-12-29                  47      664.0      658.0          659.0   \n",
       "4   5  2019-12-26                  45      668.0      654.0          657.0   \n",
       "\n",
       "   Traded Shares  Total Amount  Prev. Closing  Difference(Rs)  % Change  \n",
       "0           6310       3886900          623.0            -4.0     -0.64  \n",
       "1           3034       1896758          662.0           -39.0     -5.89  \n",
       "2          28830      19005838          659.0             3.0      0.46  \n",
       "3           6455       4254337          657.0             2.0      0.30  \n",
       "4           3815       2506070          657.0             0.0      0.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After splitting, the column 'Date' is not required. We will drop the column. We specify axis = 1 to command the function to look through the columns for 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data_training.drop(['Date'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>No. of Transaction</th>\n",
       "      <th>Max Price</th>\n",
       "      <th>Min Price</th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>Traded Shares</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Prev. Closing</th>\n",
       "      <th>Difference(Rs)</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>486</td>\n",
       "      <td>77</td>\n",
       "      <td>827.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>17490</td>\n",
       "      <td>13666590</td>\n",
       "      <td>843.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>487</td>\n",
       "      <td>150</td>\n",
       "      <td>850.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>122210</td>\n",
       "      <td>103049079</td>\n",
       "      <td>839.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>488</td>\n",
       "      <td>114</td>\n",
       "      <td>848.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>45171</td>\n",
       "      <td>37511305</td>\n",
       "      <td>860.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>489</td>\n",
       "      <td>245</td>\n",
       "      <td>867.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>82110</td>\n",
       "      <td>69226205</td>\n",
       "      <td>850.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>490</td>\n",
       "      <td>168</td>\n",
       "      <td>872.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>30830</td>\n",
       "      <td>26285395</td>\n",
       "      <td>860.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-1.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SN  No. of Transaction  Max Price  Min Price  Closing Price  \\\n",
       "485  486                  77      827.0      772.0          778.0   \n",
       "486  487                 150      850.0      837.0          843.0   \n",
       "487  488                 114      848.0      811.0          839.0   \n",
       "488  489                 245      867.0      839.0          860.0   \n",
       "489  490                 168      872.0      840.0          850.0   \n",
       "\n",
       "     Traded Shares  Total Amount  Prev. Closing  Difference(Rs)  % Change  \n",
       "485          17490      13666590          843.0           -65.0     -7.71  \n",
       "486         122210     103049079          839.0             4.0      0.48  \n",
       "487          45171      37511305          860.0           -21.0     -2.44  \n",
       "488          82110      69226205          850.0            10.0      1.18  \n",
       "489          30830      26285395          860.0           -10.0     -1.16  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1715, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.68551237e-01, 7.82608696e-01, ...,\n",
       "        8.31010453e-01, 0.00000000e+00, 1.13613614e-01],\n",
       "       [5.83430572e-04, 5.26501767e-01, 8.22608696e-01, ...,\n",
       "        8.24041812e-01, 6.16071429e-01, 5.23523524e-01],\n",
       "       [1.16686114e-03, 3.99293286e-01, 8.19130435e-01, ...,\n",
       "        8.60627178e-01, 3.92857143e-01, 3.77377377e-01],\n",
       "       ...,\n",
       "       [9.98833139e-01, 4.24028269e-02, 1.35652174e-01, ...,\n",
       "        8.36236934e-02, 9.46428571e-01, 9.94994995e-01],\n",
       "       [9.99416569e-01, 4.24028269e-02, 1.35652174e-01, ...,\n",
       "        8.36236934e-02, 9.46428571e-01, 9.94994995e-01],\n",
       "       [1.00000000e+00, 4.24028269e-02, 1.35652174e-01, ...,\n",
       "        8.36236934e-02, 9.46428571e-01, 9.94994995e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_train1 = scaler.fit_transform(df_train)\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will train the data in smaller bits of 60 days. We want to train the model with data of 60 days at a time \n",
    "\n",
    "### The loop will run the code until the training shape is 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the i is set to iterate from 60 to 1957 (current length)\n",
    "\n",
    "### It starts from i - 60 and goes until its equal to 60. In the next step, the same process if executed on y_train. \n",
    "\n",
    "### The parameters in y_train (i, 0) states the price on the 60th day\n",
    "\n",
    "### At last, we store the data into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, df_train1.shape[0]):\n",
    "    X_train.append(df_train1[i-60:i])\n",
    "    y_train.append(df_train1[i, 0])\n",
    "    \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see the shape of X_train. \n",
    "\n",
    "### It has 1897 rows \n",
    "### Divided into a list of 60  \n",
    "### each list has 10 columns i.e. attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1655, 60, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing Dependencies: Sequential, Dense, LSTM and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using Sequential model because it performs best when each layer will be provided with one input tensor and will have one output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor =Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1655, 60, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Activation function Rectified Linear Activation Function (RELU) is used bacause it is able to detect non-linear trends. \n",
    "### It also outputs the input values directly if its positive, or zero in other case. Due to these features RELU is widely used in these type of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first LSTM layer will have 60 units. i.e. memory units of each neuron.\n",
    "\n",
    "### return_sequences = True returns the full sequence in the output i.e. with hidden sequence\n",
    "\n",
    "### input_shape is set to (60, 10). This depends on out data. The dimention of our data is 60 by 10\n",
    "\n",
    "### Dropout layer prevents the model from overfitting. It limits model to certain dataset and ignores neurons while training randomly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final layer is Dense layer. It states that the neurons from that layer is completely connected to the previous layers. We have set the units value 1 because we are predicting single value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 60, activation = 'relu', return_sequences = True, input_shape = (60, 10)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 60, activation = 'relu', return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 80, activation = 'relu', return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 120, activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 60)            17040     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 60)            29040     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 80)            45120     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 80)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 120)               96480     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 121       \n",
      "=================================================================\n",
      "Total params: 187,801\n",
      "Trainable params: 187,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using 'adam' optimizer which is best for deep learning models. The loss function will be 'mean squared error'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "### We will use 100 epoch to train the model. It can be understood as no of iterations of training the model. \n",
    "### We now divide the data into batch sizes. It indicates the number of training samples used for each iteration through the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52/52 [==============================] - 7s 87ms/step - loss: 0.0659\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 5s 95ms/step - loss: 0.0042\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 5s 91ms/step - loss: 0.0038\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 5s 91ms/step - loss: 0.0039\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 5s 99ms/step - loss: 0.0028\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0026\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0029\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0023\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0024\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0022\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0025\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0021\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.1414\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.0329\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0049\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0037\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0032\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0029\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0025\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.0026\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.0025\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0022\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0021\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0021\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0020\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0019\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0021\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0018\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0018\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0018\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0018\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0017\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.0018\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0016\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0016\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 6s 123ms/step - loss: 0.0016\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0015\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.0015\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0016\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0015\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0014\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0014\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0015\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0014\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0014\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0013\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0013\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.0014\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0013\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.0013\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0013\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0012\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.0012\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0012\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.0013\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.0012\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.0011\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0011\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0010\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.0011\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0011\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 6s 123ms/step - loss: 9.8849e-04\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.0011\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0012\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 9.9846e-04\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0011\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.0010\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.0011\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.0010\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 8.5996e-04\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0011\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 9.0678e-04\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.0010\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0012\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 8.5261e-04\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 8.1151e-04\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 3.9354\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 932663.3750\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.0146\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 6s 121ms/step - loss: 0.0047\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 6s 124ms/step - loss: 0.0041\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.0042\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.0035\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.0033\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.0030\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.0029\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 8s 150ms/step - loss: 0.0028\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 8s 163ms/step - loss: 0.0030\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 8s 162ms/step - loss: 0.0025\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 8s 160ms/step - loss: 0.0029\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.0025\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 6s 122ms/step - loss: 0.0026\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 0.0024\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 0.0026\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.0024\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.0023\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.0022\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 7s 142ms/step - loss: 0.0022\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 7s 132ms/step - loss: 0.0021\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.0023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefa407bd30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.compile(optimizer='adam', loss = 'mean_squared_error')\n",
    "regressor.fit(X_train, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>Date</th>\n",
       "      <th>No. of Transaction</th>\n",
       "      <th>Max Price</th>\n",
       "      <th>Min Price</th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>Traded Shares</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Prev. Closing</th>\n",
       "      <th>Difference(Rs)</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>37</td>\n",
       "      <td>623.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>6310</td>\n",
       "      <td>3886900</td>\n",
       "      <td>623.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>39</td>\n",
       "      <td>649.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>3034</td>\n",
       "      <td>1896758</td>\n",
       "      <td>662.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>134</td>\n",
       "      <td>662.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>28830</td>\n",
       "      <td>19005838</td>\n",
       "      <td>659.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>47</td>\n",
       "      <td>664.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>6455</td>\n",
       "      <td>4254337</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>45</td>\n",
       "      <td>668.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>3815</td>\n",
       "      <td>2506070</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SN        Date  No. of Transaction  Max Price  Min Price  Closing Price  \\\n",
       "0   1  2020-01-01                  37      623.0      612.0          619.0   \n",
       "1   2  2019-12-31                  39      649.0      620.0          623.0   \n",
       "2   3  2019-12-30                 134      662.0      655.0          662.0   \n",
       "3   4  2019-12-29                  47      664.0      658.0          659.0   \n",
       "4   5  2019-12-26                  45      668.0      654.0          657.0   \n",
       "\n",
       "   Traded Shares  Total Amount  Prev. Closing  Difference(Rs)  % Change  \n",
       "0           6310       3886900          623.0            -4.0     -0.64  \n",
       "1           3034       1896758          662.0           -39.0     -5.89  \n",
       "2          28830      19005838          659.0             3.0      0.46  \n",
       "3           6455       4254337          657.0             2.0      0.30  \n",
       "4           3815       2506070          657.0             0.0      0.00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are predicting the stock price in terms of the previous 60 days. Using .tail(60), we are able to retrieve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_60_days = data_training.tail(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now append test data and ignore the index. \n",
    "### We do not need the Date column in the test set as well. So we will drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>No. of Transaction</th>\n",
       "      <th>Max Price</th>\n",
       "      <th>Min Price</th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>Traded Shares</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Prev. Closing</th>\n",
       "      <th>Difference(Rs)</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2141</td>\n",
       "      <td>3</td>\n",
       "      <td>458.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>600</td>\n",
       "      <td>273400</td>\n",
       "      <td>460.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2142</td>\n",
       "      <td>2</td>\n",
       "      <td>460.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>400</td>\n",
       "      <td>181300</td>\n",
       "      <td>458.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2143</td>\n",
       "      <td>2</td>\n",
       "      <td>458.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>360</td>\n",
       "      <td>164880</td>\n",
       "      <td>456.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2144</td>\n",
       "      <td>2</td>\n",
       "      <td>456.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>456000</td>\n",
       "      <td>456.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2145</td>\n",
       "      <td>3</td>\n",
       "      <td>456.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>700</td>\n",
       "      <td>315800</td>\n",
       "      <td>450.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SN  No. of Transaction  Max Price  Min Price  Closing Price  \\\n",
       "0  2141                   3      458.0      451.0          458.0   \n",
       "1  2142                   2      460.0      451.0          460.0   \n",
       "2  2143                   2      458.0      458.0          458.0   \n",
       "3  2144                   2      456.0      456.0          456.0   \n",
       "4  2145                   3      456.0      450.0          456.0   \n",
       "\n",
       "   Traded Shares  Total Amount  Prev. Closing  Difference(Rs)  % Change  \n",
       "0            600        273400          460.0            -2.0     -0.43  \n",
       "1            400        181300          458.0             2.0      0.44  \n",
       "2            360        164880          456.0             2.0      0.44  \n",
       "3           1000        456000          456.0             0.0      0.00  \n",
       "4            700        315800          450.0             6.0      1.33  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = past_60_days.append(data_test, ignore_index = True)\n",
    "df = df.drop(['Date'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.65577596e-01,  7.06713781e-03,  1.40869565e-01, ...,\n",
       "         1.63763066e-01,  5.62500000e-01,  4.77977978e-01],\n",
       "       [ 9.66161027e-01,  3.53356890e-03,  1.44347826e-01, ...,\n",
       "         1.60278746e-01,  5.98214286e-01,  5.21521522e-01],\n",
       "       [ 9.66744457e-01,  3.53356890e-03,  1.40869565e-01, ...,\n",
       "         1.56794425e-01,  5.98214286e-01,  5.21521522e-01],\n",
       "       ...,\n",
       "       [-1.75029172e-03,  9.54063604e-02,  7.11304348e-01, ...,\n",
       "         7.24738676e-01,  3.92857143e-01,  3.64864865e-01],\n",
       "       [-1.16686114e-03,  1.09540636e-01,  7.18260870e-01, ...,\n",
       "         7.12543554e-01,  6.42857143e-01,  5.44544545e-01],\n",
       "       [-5.83430572e-04,  1.09540636e-01,  7.35652174e-01, ...,\n",
       "         7.17770035e-01,  5.53571429e-01,  4.79979980e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = scaler.transform(df)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar to the training set, we are didiving the data into chunks of 60 days and storing it to X_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((485, 60, 10), (485,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(60, inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i])\n",
    "    y_test.append(inputs[i, 0])\n",
    "\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling.scale_ returns the scaling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.83430572e-04, 3.53356890e-03, 1.73913043e-03, 1.77619893e-03,\n",
       "       1.06382979e-03, 7.33084085e-06, 9.70454710e-09, 1.74216028e-03,\n",
       "       8.92857143e-03, 5.00500501e-02])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.scale_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We inverse the scale value and multiply it to y_pred and y_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713.999999300688"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 1/5.83430572e-04\n",
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual values are stored in the y_test and predicted values in the y_pred value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred*scale\n",
    "y_test = y_test*scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see from the graph, the model is decently accurate. The Red line represents the Real Stock Prices, whereas the blue line represents Predicted prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(y_test, color = 'red', label = 'Real NTC Stock Price')\n",
    "plt.plot(y_pred, color = 'blue', label = 'Predicted NTC Stock Price')\n",
    "plt.title('NTC Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('NTC Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stocks seem to grow on an average rate over the years. This is a very common behaviour. In most cases the average yearly growth is between 6% to 12%. \n",
    "\n",
    "### There is plenty of room for tuning and improvent for this model to get more precise results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources: \n",
    "\n",
    "- **Understanding LSTM: a tutorial into Long Short-Term Memory** by Ralf C. Staudemeyer & Eric Rothstein Morris\n",
    "- **On stock return prediction with LSTM networks** by Magnus Hansson\n",
    "- Analytics Vidhya\n",
    "- KD nuggets\n",
    "- Medium (risha-shah.medium.com)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
